{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c5381f",
   "metadata": {},
   "source": [
    "# <存放自行包好的，自定義函數區>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e713ca76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from data_process.ipynb\n",
      "importing Jupyter notebook from args.ipynb\n",
      "importing Jupyter notebook from models.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer  # 支援.ipynb檔案呼叫\n",
    "import copy # 支援deepcopy函式\n",
    "#import Main\n",
    "from itertools import chain\n",
    "\n",
    "# 自行創建之檔案 (function 或 變數 都可以import)\n",
    "from data_process import setup_seed, load_dataset, split_data, normalize_data, un_normalize_data, seq_data, batch_data, Univar_SingleStep_seq, Multivariate_SingleStep_seq, Multivariate_MultiStep_seq\n",
    "from args import Univar_SingleStep_args, Multivariate_SingleStep_args, Multivariate_MultiStep_args\n",
    "from models import LSTM, Simple_RNN, TCN, TCN_LSTM\n",
    "\n",
    "#  device還未加入\n",
    "# tqdm未確認\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "import torch\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 設置GPU (可放任意.py檔，import device即可呼叫)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b0059",
   "metadata": {},
   "source": [
    "## 固定初始化權重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecbd15f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d48a8",
   "metadata": {},
   "source": [
    "## 運行data_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af51993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args, seq_method):  # \n",
    "    if seq_method == 'us':\n",
    "        Train_seq, Val_seq, Test_seq, m, n = Univar_SingleStep_seq(args.seq_len, args.batch_size)  # shape = (batch_size, 2)\n",
    "    elif seq_method == 'ms':\n",
    "        Train_seq, Val_seq, Test_seq, m, n = Multivariate_SingleStep_seq(args.seq_len, args.batch_size)\n",
    "    elif seq_method == 'mm':\n",
    "        Train_seq, Val_seq, Test_seq, m, n = Multivariate_MultiStep_seq(args.seq_len, args.batch_size, args.output_size, args.output_size)\n",
    "\n",
    "    return Train_seq, Val_seq, Test_seq, m, n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb523bbe",
   "metadata": {},
   "source": [
    "## 查看模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_model_shape(model):\n",
    "    print(\"查看模型結構:\\n\",model)\n",
    "    print(\"\\n查看網路參數:\")\n",
    "    for name, parameters in model.named_parameters():\n",
    "        print(name, ':', parameters.size())\n",
    "    print(\"--------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3557953",
   "metadata": {},
   "source": [
    "## 驗證模型loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9368085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss(model, Val_data):\n",
    "    model.eval()\n",
    "    loss_function = nn.MSELoss().to(device)\n",
    "    val_loss = []\n",
    "    for (seq, label) in Val_data:\n",
    "        seq = seq.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        with torch.no_grad():  # 不計算梯度\n",
    "            y_pred = model(seq)\n",
    "            loss = loss_function(y_pred, label)\n",
    "            val_loss.append(loss.item())\n",
    "    return np.mean(val_loss)  # 取所有loss平均值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed33752",
   "metadata": {},
   "source": [
    "## 計算模型分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b577d359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(y, pred):\n",
    "    \"\"\"\n",
    "    y: 正確值\n",
    "    pred: 預測值\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs((y - pred) / y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a9c8ab",
   "metadata": {},
   "source": [
    "## 畫圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ece680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def get_plot2(y, pred):\n",
    "    x = [i for i in range(1, 151)]\n",
    "    x_smooth = np.linspace(np.min(x), np.max(x), 900)  # 在 a 到 b 之間產生 900 個點\n",
    "    y_smooth = make_interp_spline(x, y[150:300])(x_smooth)  # 變成平滑的曲線\n",
    "    plt.plot(x_smooth, y_smooth, c='green', marker='*', ms=1, alpha=0.75, label='true')\n",
    "\n",
    "    y_smooth = make_interp_spline(x, pred[150:300])(x_smooth)\n",
    "    plt.plot(x_smooth, y_smooth, c='red', marker='o', ms=1, alpha=0.75, label='pred')\n",
    "    plt.grid(axis='y')\n",
    "    plt.legend()\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "def get_plot(y, pred):\n",
    "    # 可視化部分結果\n",
    "    x = [i for i in range(1, 151)]\n",
    "    plt.plot(x, y[150:300], c='green', marker='*', ms=1, alpha=0.75, label='true')\n",
    "    plt.plot(x, pred[150:300], c='red', marker='o', ms=1, alpha=0.75, label='pred')\n",
    "    #plt.figure(figsize = (8,5))\n",
    "    #plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=8))  # 設定x軸刻度間距 \n",
    "    #plt.plot( x , y, label='check_out_gt')\n",
    "    #plt.plot( x , pred, label='check_out_pred')\n",
    "\n",
    "    plt.xlabel(\"date(part interval)\")\n",
    "    plt.ylabel(\"load\")\n",
    "    #plt.xticks(rotation=30)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc13bd2b",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0658b637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, Train_data, Val_data, model_path, model_method):\n",
    "    input_size, hidden_size, num_layers = args.input_size, args.hidden_size, args.num_layers\n",
    "    output_size = args.output_size\n",
    "    # MODEL\n",
    "    if model_method == 'LSTM':\n",
    "        model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=args.batch_size).to(device)  # 在GPU跑\n",
    "    elif model_method == 'TCN':\n",
    "        #model = TCN(input_size, output_size, [64,128], 2, 0.1).to(device) \n",
    "        model = TCN(input_size, output_size, [8,25], 6, 0.1).to(device)  \n",
    "\n",
    "    # 查看模型結構\n",
    "    look_model_shape(model)\n",
    "    # LOSS\n",
    "    loss_function = nn.MSELoss().to(device)  # MSE loss\n",
    "    # OPTIMIZER\n",
    "    if args.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(params=model.parameters(), lr=args.lr, weight_decay=args.weight_decay)  # 設定optimization\n",
    "    # LR\n",
    "    scheduler = StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "    \n",
    "    # 訓練開始\n",
    "    min_epochs = 5  # 最小保存回合\n",
    "    min_val_loss = 5\n",
    "    best_model = None\n",
    "    for epoch in tqdm(range(args.epochs)):\n",
    "        train_loss = []  # 紀錄loss值\n",
    "        model.train()\n",
    "        for (seq, label) in Train_data:\n",
    "            seq = seq.to(device)  # 在GPU跑\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # y_pred: 預測結果\n",
    "            y_pred = model(seq)  # 將data傳入model進行forward propagation\n",
    "            loss = loss_function(y_pred, label)  # 計算loss\n",
    "            train_loss.append(loss.item())  # 保存loss結果 -> .item()很重要，取值\n",
    "            \n",
    "            optimizer.zero_grad()  # 清空前一次的gradient\n",
    "            loss.backward()  # 根據loss進行back propagation，計算gradient\n",
    "            optimizer.step()  # 做gradient descent，根據gradient descent更新所有網路參數\n",
    "\n",
    "            # zero_grad()和backward()使用技巧、Truncated Back Propagation Through Time技術\n",
    "            ## 參考: https://meetonfriday.com/posts/18392404/\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 驗證\n",
    "        val_loss = get_val_loss(model, Val_data)  # ~get_val_loss\n",
    "        if epoch + 1 >= min_epochs and val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            best_model = copy.deepcopy(model)  # 需import copy\n",
    "        \n",
    "        \n",
    "        print('epoch {:03d} train_loss {:.8f} val_loss{:.8f}'.format(epoch, np.mean(train_loss), val_loss))\n",
    "        \n",
    "    \n",
    "    save_model = {'models': best_model.state_dict()}  # 標籤: models\n",
    "    torch.save(save_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca920c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ff6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, Test_data, m, n, model_path, model_method):  # 需可獨立執行\n",
    "    pred = []  # 預測值\n",
    "    y = []  # 正確值\n",
    "    \n",
    "    print('Loading Model...')\n",
    "    input_size, hidden_size, num_layers = args.input_size, args.hidden_size, args.num_layers\n",
    "    output_size = args.output_size\n",
    "    # MODEL\n",
    "    # MODEL\n",
    "    if model_method == 'LSTM':\n",
    "        model = LSTM(input_size, hidden_size, num_layers, output_size, batch_size=args.batch_size).to(device)  # 在GPU跑\n",
    "    elif model_method == 'TCN':\n",
    "        #model = TCN(input_size, output_size, [64,128], 2, 0.1).to(device) \n",
    "        model = TCN(input_size, output_size, [8,25], 6, 0.1).to(device) \n",
    "        \n",
    "    model.load_state_dict(torch.load(model_path)['models'])  # 加載模型參數\n",
    "    model.eval()\n",
    "    \n",
    "    print('Start predicting...')\n",
    "    for (seq, label) in tqdm(Test_data):\n",
    "        \"\"\"\n",
    "        seq: =final_seq[][0]   -> (x,x,x,x,x,x,x)\n",
    "        label: =final_seq[][1] -> (y)\n",
    "        y_pred: 預測結果，shape等同於label(Ground True)\n",
    "        \"\"\"\n",
    "        label = list(chain.from_iterable(label.data.tolist()))  # 嵌套列表 → 合併單一列表\n",
    "        y.extend(label)\n",
    "        seq = seq.to(device)  # 進模型資料，用GPU跑\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(seq)\n",
    "            #print(\"before: \",y_pred[0:10])\n",
    "            #y_pred = y_pred.data.tolist()\n",
    "            #print(\"after: \",y_pred[0:10])\n",
    "            y_pred = list(chain.from_iterable(y_pred.data.tolist()))\n",
    "            #pred.append(y_pred)  # extend v.s. append: https://sean22492249.medium.com/python-list-的-extend-append-的差別-5dd4a585aafe\n",
    "            pred.extend(y_pred)\n",
    "            \n",
    "    # pred shape = (  , batch_size, 2) # 未確認結構\n",
    "\n",
    "    # 還原正規化\n",
    "    y, pred = un_normalize_data(y, pred, m, n)  # ~un_normalize_data\n",
    "    print(\"y_shape: \",y.shape)\n",
    "    print(\"pred_shape: \",pred.shape)\n",
    "    print(\"\\ny_value: \",y[0:10])\n",
    "    print(\"pred_value: \",pred[0:10],\"\\n\")\n",
    "    print(\"mape:\", get_mape(y, pred))  # ~get_mape\n",
    "    \n",
    "    get_plot(y, pred)  # 顯示分析結果  ~get_plot\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d95c60fc",
   "metadata": {},
   "source": [
    "# 解讀\n",
    "from itertools import chain\n",
    "y = [[0.4972],[0.4642],[0.4130],[0.3972],[0.3670],[0.3221]]\n",
    "#from_iterable = chain.from_iterable(['geeks', 'for', 'fafa'])\n",
    "from_iterable = chain.from_iterable(np.array(y).data.tolist())\n",
    "print(list(from_iterable))\n",
    "#打印结果\n",
    "# [0.4972, 0.4642, 0.413, 0.3972, 0.367, 0.3221]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09630330",
   "metadata": {},
   "source": [
    "# 單獨測試用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4335b123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len: 7\n",
      "總列數: (3000, 8)\n",
      "序列化_seq_data: (2993, 2)\n",
      "\n",
      "示範:\n",
      "seq: tensor([[0.6209],\n",
      "        [0.5890],\n",
      "        [0.6001],\n",
      "        [0.6056],\n",
      "        [0.6782],\n",
      "        [0.6538],\n",
      "        [0.7577]])\n",
      "label: tensor([0.7906]) \n",
      "----------------------------\n",
      "\n",
      "seq_len: 7\n",
      "總列數: (1000, 8)\n",
      "序列化_seq_data: (993, 2)\n",
      "\n",
      "示範:\n",
      "seq: tensor([[0.4345],\n",
      "        [0.4440],\n",
      "        [0.4058],\n",
      "        [0.4105],\n",
      "        [0.3603],\n",
      "        [0.3877],\n",
      "        [0.5956]])\n",
      "label: tensor([0.6223]) \n",
      "----------------------------\n",
      "\n",
      "seq_len: 7\n",
      "總列數: (1000, 8)\n",
      "序列化_seq_data: (993, 2)\n",
      "\n",
      "示範:\n",
      "seq: tensor([[0.6854],\n",
      "        [0.6605],\n",
      "        [0.6447],\n",
      "        [0.6572],\n",
      "        [0.6823],\n",
      "        [0.5961],\n",
      "        [0.4972]])\n",
      "label: tensor([0.4261]) \n",
      "----------------------------\n",
      "\n",
      "epoch 000 train_loss 0.29345316 val_loss0.46423262\n",
      "epoch 001 train_loss 0.29345316 val_loss0.46423262\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24972\\30615290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mUnivar_SingleStep_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mTrain_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVal_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTest_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'us'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ~load_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_TCN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrain_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVal_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# ~train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24972\\1926925249.py\u001b[0m in \u001b[0;36mtrain_TCN\u001b[1;34m(args, Train_data, Val_data, model_path)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[1;31m# y_pred: 預測結果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 將data傳入model進行forward propagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 計算loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 保存loss結果 -> .item()很重要，取值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\其他電腦\\我的筆記型電腦\\NCKU\\Coding\\Cc\\Self_Learn\\RNN系列實作\\電力能耗負載預測\\models.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\其他電腦\\我的筆記型電腦\\NCKU\\Coding\\Cc\\Self_Learn\\RNN系列實作\\電力能耗負載預測\\models.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\其他電腦\\我的筆記型電腦\\NCKU\\Coding\\Cc\\Self_Learn\\RNN系列實作\\電力能耗負載預測\\models.ipynb\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1118\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1120\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py37\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m    297\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[1;32m--> 298\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 單獨測試train\n",
    "if __name__ == '__main__':  #加入這個，被import時，不會執行def以外的code，自己執行才會呼叫\n",
    "    model_path = './save_models/Univar_SingleStep.pkl'\n",
    "    args = Univar_SingleStep_args()\n",
    "    Train_seq, Val_seq, Test_seq, m, n = load_data(args, 'us')  # ~load_data\n",
    "    train(args, Train_seq, Val_seq, model_path, 'LSTM')  # ~train\n",
    "    \n",
    "\"\"\"\n",
    "參考: https://ithelp.ithome.com.tw/articles/10277352\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3473ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 單獨測試test\n",
    "if __name__ == '__main__':\n",
    "    model_path = './save_models/Univar_SingleStep.pkl'\n",
    "    args = Univar_SingleStep_args() \n",
    "    Train_seq, Val_seq, Test_seq, m, n = load_data(args, 'us')  # ~load_data\n",
    "    test(args, Test_seq, m, n, model_path, 'LSTM')  # ~test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
